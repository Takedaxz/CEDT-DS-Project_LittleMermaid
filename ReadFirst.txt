##การทำความเข้าใจโจทย์ในโครงการนี้เป็นขั้นตอนสำคัญเพื่อให้ทุกคนในทีมเห็นภาพรวมของสิ่งที่ต้องทำอย่างชัดเจน โดยในโครงการนี้ เราควรให้ความสำคัญใน 3 ด้านหลัก ได้แก่ วัตถุประสงค์ของโครงการ โครงสร้างของ pipeline และ เกณฑ์ที่โครงการต้องมี เพื่อวางแผนและกำหนดทิศทางการทำงานให้เป็นไปในแนวทางเดียวกัน

1. วัตถุประสงค์ของโครงการ
วัตถุประสงค์ของโครงการนี้คือ การวิเคราะห์แนวโน้มและเครือข่ายการวิจัยด้านวิศวกรรมในระดับโลก ตั้งแต่ปี 2018 ถึง 2023 โดยเน้นการหาข้อมูลเชิงลึกเกี่ยวกับหัวข้องานวิจัยที่กำลังได้รับความสนใจ การกระจายตัวทางภูมิศาสตร์ของงานวิจัย และการเชื่อมโยงเครือข่ายของผู้ร่วมเขียนหรือสถาบันต่าง ๆ การตั้งเป้าหมายนี้จะช่วยให้การวิเคราะห์และการแสดงข้อมูลสามารถตอบคำถามและให้ข้อมูลเชิงลึกที่มีคุณค่าต่อการวิจัยในสาขานี้

2. โครงสร้าง Pipeline ของโครงการ
โครงสร้าง pipeline ในโครงการนี้มีหลายขั้นตอนที่ทำงานต่อเนื่องกันตั้งแต่ต้นจนจบ ซึ่งประกอบไปด้วย:
    การรวบรวมข้อมูล (Data Ingestion): นำเข้าข้อมูลจาก Scopus ที่ได้มา รวมถึงการดึงข้อมูลเพิ่มเติมจาก Google Scholar หรือ DBLP โดยอาจใช้การดึงข้อมูลจาก API หรือการ web scraping
    การประมวลผลและจัดการข้อมูล (Data Engineering): ทำความสะอาดข้อมูล และจัดระเบียบข้อมูลให้อยู่ในรูปแบบที่พร้อมสำหรับการวิเคราะห์ โดยต้องมีการแยกฟีลด์สำคัญ เช่น ชื่อบทความ บทคัดย่อ วันที่เผยแพร่ และสังกัดผู้เขียน
    การวิเคราะห์ AI/ML (AI/ML Analysis): นำเทคนิคการวิเคราะห์ AI และ Machine Learning เช่น Topic Modeling เพื่อจัดกลุ่มหัวข้อวิจัย และ Sentiment Analysis เพื่อวิเคราะห์แนวโน้มของอารมณ์ในเนื้อหาของบทความ
    การแสดงข้อมูล (Visualization): นำเสนอผลการวิเคราะห์โดยใช้เครื่องมือเช่น Power BI หรือ Tableau เพื่อสร้างแผนที่ภูมิศาสตร์ของแหล่งวิจัย กราฟเครือข่ายของผู้เขียน และกราฟแนวโน้มของหัวข้อการวิจัยในช่วงเวลาต่าง ๆ
3. เกณฑ์ที่โครงการต้องมี
โครงการนี้มีเงื่อนไขสำคัญที่ต้องปฏิบัติตาม ดังนี้:
    จำนวนสมาชิก: สมาชิกในทีมสามารถมีได้สูงสุด 6 คน
    องค์ประกอบขั้นต่ำที่ต้องมีใน pipeline:
        มีส่วนของ AI/ML อย่างน้อยหนึ่งส่วน
        มีส่วนของ Data Engineering อย่างน้อยหนึ่งส่วน
        มีส่วนของการสร้างภาพอย่างน้อยหนึ่งส่วน ซึ่งต้องประกอบด้วยการวิเคราะห์ทางภูมิศาสตร์หรือการสร้างภาพเครือข่าย
    ข้อมูลเพิ่มเติมที่ต้องหา: นอกจากข้อมูลที่ได้รับจาก Scopus ยังต้องเพิ่มข้อมูลวิจัยจากแหล่งภายนอกให้ได้อย่างน้อย 1,000 บทความ
    คุณค่าของข้อมูลเสริม: การเพิ่มข้อมูลเชิงพื้นที่ เช่น สถานที่หรือสังกัดของผู้เขียน จะช่วยเพิ่มความน่าสนใจและอาจได้คะแนนเพิ่มในโครงการ

##การเริ่มต้นโครงการนี้สามารถแบ่งเป็นขั้นตอนย่อยเพื่อให้จัดการได้ง่ายขึ้น ดังนี้:

1. วางแผนและกำหนดโครงสร้าง (Planning and Structuring)
ทำความเข้าใจโจทย์: วิเคราะห์วัตถุประสงค์ โครงสร้าง pipeline และเกณฑ์ที่โครงการต้องมี เพื่อให้แน่ใจว่าทุกคนในทีมเข้าใจทิศทางและขั้นตอนของโครงการเหมือนกัน
กำหนดขอบเขตของงาน: แบ่งส่วนงานออกเป็นขั้นตอนต่าง ๆ เช่น การรวบรวมข้อมูล การประมวลผลข้อมูล การวิเคราะห์ด้วย AI และการสร้างภาพ
แบ่งงานในทีม: จัดกลุ่มสมาชิกให้รับผิดชอบในแต่ละส่วนตามความถนัด เช่น คนที่เชี่ยวชาญในการจัดการข้อมูลทำในส่วน Data Engineering หรือคนที่ถนัด NLP และการสร้างภาพทำในส่วน AI/ML และ Visualization
2. การรวบรวมข้อมูล (Data Collection)
ตรวจสอบไฟล์ Scopus: ตรวจสอบโครงสร้างข้อมูลในไฟล์ Scopus ที่ได้มา (JSON) ว่ามีฟีลด์ไหนที่จำเป็นและมีข้อมูลที่เป็นประโยชน์ เช่น ชื่อบทความ บทคัดย่อ คำสำคัญ สังกัด และอื่น ๆ
รวบรวมข้อมูลเพิ่มเติม: ใช้ web scraping หรือ API จากแหล่งภายนอก เช่น Google Scholar หรือ DBLP เพื่อเพิ่มบทความประมาณ 1,000 บทความ ให้ได้ข้อมูลเพียงพอตามที่กำหนด
ทำความสะอาดและจัดระเบียบข้อมูลเบื้องต้น: ทำความสะอาดข้อมูลเบื้องต้น เช่น การจัดการกับค่า missing values หรือการกำจัดข้อมูลซ้ำ เพื่อให้ง่ายต่อการประมวลผลในขั้นตอนถัดไป
3. การจัดการข้อมูล (Data Engineering)
ออกแบบโครงสร้างข้อมูล (Data Schema): กำหนด schema ของข้อมูล เช่น ฟีลด์ต่าง ๆ ที่จะใช้สำหรับการวิเคราะห์ เพื่อให้การดึงข้อมูลเป็นไปอย่างมีระบบ
เตรียมข้อมูลให้พร้อมใช้: แปลงและจัดข้อมูลให้มีรูปแบบที่เหมาะสมกับการวิเคราะห์ เช่น การแยกข้อมูลตามฟีลด์ที่ต้องใช้ การแปลงฟอร์แมตเวลา และการคำนวณค่าเพิ่มเติมถ้าจำเป็น
สร้าง workflow management: เริ่มใช้งาน Airflow เพื่อควบคุมกระบวนการ pipeline ให้แต่ละขั้นตอนดำเนินไปได้อย่างต่อเนื่อง
4. การวิเคราะห์ข้อมูลด้วย AI/ML
เลือกเทคนิคการวิเคราะห์ (AI/ML Technique): พิจารณาเทคนิค NLP เช่น Topic Modeling เพื่อวิเคราะห์หัวข้อและ Sentiment Analysis สำหรับการวิเคราะห์อารมณ์ของบทคัดย่อหรือหัวข้อ
ฝึกแบบจำลอง (Model Training): เตรียมข้อมูลและฝึกแบบจำลองการจำแนกหัวข้อบทความหรือวิเคราะห์แนวโน้ม เพื่อให้ได้ข้อมูลเชิงลึกที่แม่นยำ
ทดสอบและประเมินผล (Evaluation): ตรวจสอบประสิทธิภาพของแบบจำลองที่สร้างขึ้น เช่น ความถูกต้องของการจำแนกหัวข้อหรือแนวโน้มของข้อมูล เพื่อปรับปรุงคุณภาพของผลลัพธ์
5. การสร้างภาพข้อมูล (Visualization)
เตรียมเครื่องมือสร้างภาพ: เลือกเครื่องมือที่เหมาะสม เช่น Power BI หรือ Tableau เพื่อให้การแสดงข้อมูลมีประสิทธิภาพและสามารถโต้ตอบได้
ออกแบบแดชบอร์ด (Dashboard Design): กำหนดองค์ประกอบในการแสดงข้อมูล เช่น แผนที่ภูมิศาสตร์แสดงศูนย์กลางการวิจัย กราฟเครือข่ายของผู้เขียน และแผนภูมิแนวโน้มการวิจัย
ทดสอบการใช้งาน: ตรวจสอบว่าการแสดงผลข้อมูลในแดชบอร์ดมีความชัดเจนและใช้งานได้ง่าย เพื่อให้การนำเสนอข้อมูลมีประสิทธิภาพมากที่สุด
6. การนำเสนอผลลัพธ์ (Presentation)
จัดทำรายงานหรือสไลด์: สรุปผลการวิเคราะห์และข้อมูลเชิงลึกในรูปแบบรายงานหรือสไลด์เพื่อนำเสนอต่อทีมอาจารย์หรือผู้ที่สนใจ
เตรียมการนำเสนอ: ฝึกการนำเสนอและอธิบายกระบวนการและผลลัพธ์อย่างชัดเจน รวมถึงแนวทางและอุปสรรคที่พบในแต่ละขั้นตอน


##โครงการ: แนวโน้มและเครือข่ายงานวิจัยด้านวิศวกรรมในระดับโลก
1. วัตถุประสงค์
เพื่อวิเคราะห์แนวโน้มการวิจัยด้านวิศวกรรมทั่วโลกตั้งแต่ปี 2018 ถึง 2023 โดยเน้นไปที่หัวข้องานวิจัย การกระจายตัวทางภูมิศาสตร์ เครือข่ายผู้ร่วมเขียน และบทความที่มีอิทธิพลสูง โครงการนี้จะใช้เทคนิคด้านวิทยาศาสตร์ข้อมูลขั้นสูงเพื่อระบุหัวข้อการวิจัยหลัก รูปแบบการทำงานร่วมกัน และหัวข้อที่กำลังเกิดใหม่ เพื่อให้มหาวิทยาลัยและนักวิจัยเข้าใจแนวโน้มของการวิจัยด้านวิศวกรรมในระดับโลก

2. ภาพรวมของขั้นตอนการทำงาน (Pipeline)
การเก็บข้อมูล: นำเข้าข้อมูลเมทาดาทาจาก Scopus ที่ได้รับมาและเพิ่มข้อมูลที่ขูดหรือนำมาจากแหล่งภายนอก เช่น Google Scholar หรือ DBLP โดยใช้ API
การจัดการข้อมูล (Data Engineering): ประมวลผลและทำความสะอาดไฟล์ JSON และดึงข้อมูลที่เกี่ยวข้อง เช่น ชื่อบทความ บทคัดย่อ วันที่เผยแพร่ สังกัด คำสำคัญ
AI/ML: ใช้เทคนิค NLP เช่น Topic Modeling (LDA หรือ BERT) เพื่อจำแนกเอกสารการวิจัยตามหัวข้อและค้นหาหัวข้อใหม่ที่กำลังเกิดขึ้น
การสร้างภาพ (Visualization): ใช้ Power BI หรือ Tableau เพื่อแสดงผลข้อมูล เช่น แผนที่ภูมิศาสตร์ของแหล่งวิจัยหลักและเครือข่ายความร่วมมือระหว่างผู้เขียน
3. รายละเอียดขององค์ประกอบต่าง ๆ
องค์ประกอบที่ 1 (AI/ML): NLP และ Topic Modeling
ทำการจัดกลุ่มหัวข้อวิจัยจากบทคัดย่อเพื่อระบุแนวทางการวิจัยหลักด้านวิศวกรรม
วิเคราะห์อารมณ์ของหัวเรื่องหรือบทคัดย่อเพื่อเข้าใจทิศทางการวิจัย
องค์ประกอบที่ 2 (Data Engineering): การดึงและประมวลผลข้อมูล
ประมวลผลข้อมูลจาก Scopus และเพิ่มบทความมากกว่า 1,000 บทความจาก Google Scholar หรือ DBLP
รวมข้อมูลเพิ่มเติม เช่น ที่ตั้งของผู้เขียนหรือสังกัด เพื่อเสริมความน่าสนใจของโครงการ
องค์ประกอบที่ 3 (Visualization): การวิเคราะห์แผนที่ภูมิศาสตร์และเครือข่าย
สร้างแผนที่ภูมิศาสตร์เพื่อแสดงศูนย์กลางการวิจัยหรือสถาบันวิจัยชั้นนำ
สร้างกราฟเครือข่ายเพื่อแสดงความร่วมมือของผู้เขียนและไฮไลท์ผู้เขียนหรือสถาบันที่มีอิทธิพล
4. ฟีเจอร์เพิ่มเติม (ไม่บังคับแต่แนะนำเพื่อความลึกของโครงการ)
การวิเคราะห์เชิงเวลา: ติดตามแนวโน้มการวิจัยในช่วงเวลาต่าง ๆ แสดงการเติบโตหรือถดถอยของหัวข้อนั้น ๆ
การวิเคราะห์การอ้างอิง: ระบุบทความที่ถูกอ้างอิงมากที่สุดและวิเคราะห์ผลกระทบของบทความเหล่านั้นตามเวลา
การวิเคราะห์อารมณ์: วิเคราะห์อารมณ์จากบทคัดย่อเพื่อดูว่ามีแนวโน้มเป็นเชิงบวก กลาง ๆ หรือเชิงลบในแต่ละสาขาการวิจัย
5. ขั้นตอนของโครงการ
การนำเข้าข้อมูล: ใช้ API หรือเครื่องมือการขูดข้อมูลเพื่อรวบรวมข้อมูลเพิ่มเติม
การจัดการเวิร์กโฟลว์: ใช้ Apache Airflow เพื่อควบคุมการทำงานของ pipeline
การประมวลผลข้อมูล: ทำความสะอาดและโครงสร้างข้อมูลด้วย Python และ Spark
การสร้างแบบจำลอง AI: ใช้เทคนิค NLP ในการวิเคราะห์หัวข้อและอารมณ์
การสร้างภาพและการนำเสนอ: นำเสนอข้อมูลใน Power BI ที่มีองค์ประกอบแบบโต้ตอบ
6. ข้อมูลเชิงลึกและคุณค่าที่คาดหวัง
แนวโน้มการวิจัย: ข้อมูลเชิงลึกเกี่ยวกับหัวข้อวิจัยด้านวิศวกรรมที่กำลังเป็นที่นิยม
เครือข่ายความร่วมมือ: แสดงภาพเครือข่ายความร่วมมือระหว่างผู้เขียนและสถาบัน
ข้อมูลเชิงภูมิศาสตร์: แผนที่แสดงศูนย์กลางการวิจัย ช่วยให้ผู้ที่สนใจเห็นภาพของอิทธิพลการวิจัยในระดับโลก